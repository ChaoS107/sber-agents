## Прогресс по итерациям

| Итерация | Описание                                       | Статус  | Иконка |
|----------|-------------------------------------------------|---------|--------|
| 1        | Каркас бота и эхо-ответ без LLM                | ✅ DONE | ✅     |
| 2        | Интеграция с LLM через OpenRouter              | ✅ DONE | ✅     |
| 3        | Контекст диалога в памяти                      | ✅ DONE | ✅     |
| 4        | Команды `/start`, `/help`, базовые подсказки   | ✅ DONE | ✅     |
| 5        | Команда `/reset` и чистый сброс контекста      | ✅ DONE | ✅     |
| 6        | Конфигурация через `.env` и `config.py`        | ✅ DONE | ✅     |
| 7        | Логирование и финальная проверка сценариев     | ✅ DONE | ✅     |

> Примечание: после завершения каждой итерации обновляем таблицу (столбцы **Статус** и **Иконка**).

---

## Итерационный план разработки

### Итерация 1 — Каркас бота и эхо-ответ без LLM

- [x] Настроить `pyproject.toml` и зависимости через `uv` (Python 3.11, `aiogram`, `openai` пока можно не использовать).
- [x] Создать `src/bot.py` с минимальной инициализацией `aiogram` и запуском `polling`.
- [x] Реализовать обработку обычных текстовых сообщений: бот отвечает тем же текстом (эхо).
- [ ] Проверить работу в Telegram с тестовым токеном (ручной запуск).

### Итерация 2 — Интеграция с LLM через OpenRouter

- [x] Добавить зависимости и модуль `src/llm.py` с системным промптом и функцией `ask_llm`.
- [x] Подключить `openai` к OpenRouter, использовать базовый URL и модель из окружения.
- [x] Изменить обработчик сообщений в `bot.py`: вместо эхо отправлять ответ от LLM.
- [x] Протестировать диалог в Telegram (одиночные запросы без учёта истории).

### Итерация 3 — Контекст диалога в памяти

- [x] Добавить in-memory структуру `dialog_context` в `bot.py` для хранения истории по `user_id`.
- [x] При каждом сообщении обновлять историю и обрезать её до последних 6–10 сообщений.
- [x] Передавать историю в `ask_llm` для формирования контекста.
- [ ] Проверить, что бот учитывает предыдущие сообщения в рамках одного чата.

### Итерация 4 — Команды `/start` и `/help`

- [x] Реализовать обработчик команды `/start`: приветствие, описание роли, примеры запросов.
- [x] Реализовать обработчик команды `/help`: краткая справка по возможностям бота.
- [x] Убедиться, что обычные текстовые сообщения продолжают работать как диалог с LLM.
- [x] Пройти сценарии `/start` → вопрос → уточняющий вопрос → `/help`.

### Итерация 5 — Команда `/reset` и сброс контекста

- [x] Добавить обработчик команды `/reset`, очищающий контекст для текущего `user_id`.
- [x] Отправлять пользователю понятное подтверждение о сбросе.
- [x] Проверить: до `/reset` бот помнит предыдущие сообщения, после `/reset` начинает «с нуля`.

### Итерация 6 — Конфигурация через `.env` и `config.py`

- [x] Создать `src/config.py` для чтения переменных окружения (токены, ключи, URL, модель, уровень логов).
- [x] Заменить прямые обращения к `os.environ` на использование `config.py`.
- [x] Убедиться, что при отсутствии критичных переменных приложение падает с понятной ошибкой.
- [x] Обновить `Makefile` / инструкции запуска с учётом `.env`.

### Итерация 7 — Логирование и финальная проверка сценариев

- [x] Настроить базовое логирование в `bot.py` через `logging.basicConfig` (формат, уровень из `LOG_LEVEL`).
- [x] Логировать запуск бота, входящие сообщения, вызовы LLM и ошибки.
- [ ] Пройти все ключевые сценарии: `/start`, `/help`, обычный диалог, `/reset`, ситуации с ошибкой LLM.
- [x] Зафиксировать состояние в отчёте (обновить таблицу прогресса выше).


